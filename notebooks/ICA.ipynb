{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "import scipy.io as sio\n",
    "from scipy.linalg import eig, sqrtm, inv\n",
    "import pdb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cjade(X, m=None, max_iter=200):\n",
    "    # Source separation of complex signals with JADE.\n",
    "    # Jade performs `Source Separation' in the following sense:\n",
    "    #   X is an n x T data matrix assumed modelled as X = A S + N where\n",
    "    # \n",
    "    # o A is an unknown n x m matrix with full rank.\n",
    "    # o S is a m x T data matrix (source signals) with the properties\n",
    "    #      a) for each t, the components of S(:,t) are statistically\n",
    "    #         independent\n",
    "    #   b) for each p, the S[p,:] is the realization of a zero-mean\n",
    "    #      `source signal'.\n",
    "    #   c) At most one of these processes has a vanishing 4th-order\n",
    "    #     cumulant.\n",
    "    # o  N is a n x T matrix. It is a realization of a spatially white\n",
    "    #    Gaussian noise, i.e. Cov(X) = sigma*eye(n) with unknown variance\n",
    "    #    sigma.  This is probably better than no modeling at all...\n",
    "    #\n",
    "    # Jade performs source separation via a \n",
    "    # Joint Approximate Diagonalization of Eigen-matrices.  \n",
    "    #\n",
    "    # THIS VERSION ASSUMES ZERO-MEAN SIGNALS\n",
    "    #\n",
    "    # Input :\n",
    "    #   * X: Each column of X is a sample from the n sensors (time series' in rows)\n",
    "    #   * m: m is an optional argument for the number of sources.\n",
    "    #     If ommited, JADE assumes as many sources as sensors.\n",
    "    #\n",
    "    # Output :\n",
    "    #    * A is an n x m estimate of the mixing matrix\n",
    "    #    * S is an m x T naive (ie pinv(A)*X)  estimate of the source signals\n",
    "    #\n",
    "    #\n",
    "    # Version 1.6.  Copyright: JF Cardoso.  \n",
    "    # Translated to Python by Michael A. Casey, Bregman Labs, All Rights Reserved\n",
    "    # See notes, references and revision history at the bottom of this file\n",
    "\n",
    "\n",
    "\n",
    "    # Copyright (c) 2013, Jean-Francois Cardoso\n",
    "    # All rights reserved.\n",
    "    #\n",
    "    #\n",
    "    # BSD-like license.\n",
    "    # Redistribution and use in source and binary forms, with or without modification, \n",
    "    # are permitted provided that the following conditions are met:\n",
    "    #\n",
    "    # Redistributions of source code must retain the above copyright notice, \n",
    "    # this list of conditions and the following disclaimer.\n",
    "    #\n",
    "    # Redistributions in binary form must reproduce the above copyright notice,\n",
    "    # this list of conditions and the following disclaimer in the documentation \n",
    "    # and/or other materials provided with the distribution.\n",
    "    #\n",
    "    #\n",
    "    # THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS \n",
    "    # OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY\n",
    "    # AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER \n",
    "    # OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\n",
    "    # DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, \n",
    "    # DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER \n",
    "    # IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT \n",
    "    # OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "    if type(X) is not np.matrixlib.defmatrix.matrix:\n",
    "        X = np.matrix(X, dtype=np.complex_)\n",
    "    n,T = X.shape\n",
    "\n",
    "    #  source detection not implemented yet !\n",
    "    m = n if m is None else m\n",
    "\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    # A few parameters that could be adjusted\n",
    "    nem = m # number of eigen-matrices to be diagonalized\n",
    "    seuil = 1/np.sqrt(T)/100. # a statistical threshold for stopping joint diag\n",
    "\n",
    "    if m < n :  # assumes white noise\n",
    "            D, U = eig((X*X.H)/T)\n",
    "            k = np.argsort(D)\n",
    "            puiss = D[k]\n",
    "            ibl = np.sqrt(puiss[n-m:n]-puiss[:n-m].mean())\n",
    "            bl = np.ones((m,1), dtype=np.complex_) / ibl \n",
    "            W = np.diag(np.diag(bl))*np.matrix(U[:n,k[n-m:n]]).H\n",
    "            IW = np.matrix(U[:n,k[n-m:n]])*np.diag(ibl)\n",
    "    else:    # assumes no noise\n",
    "            IW = sqrtm((X*X.H)/T)\n",
    "            W = inv(IW)\n",
    "    Y = W * X\n",
    "\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    #%% Cumulant estimation\n",
    "\n",
    "\n",
    "    R = (Y*Y.H)/T\n",
    "    C = (Y*Y.T)/T\n",
    "\n",
    "    czeros = lambda dim: np.matrix(np.zeros(dim, dtype=np.complex_)) # Initialize complex matrices\n",
    "    ceye = lambda sz: np.matrix(np.eye(sz, dtype=np.complex_))\n",
    "\n",
    "    Yl = czeros((1,T))\n",
    "    Ykl = czeros((1,T))\n",
    "    Yjkl = czeros((1,T))\n",
    "\n",
    "    Q = czeros((m*m*m*m,1))\n",
    "    index = 0\n",
    "\n",
    "    for lx in np.arange(m):\n",
    "        Yl = Y[lx,:]\n",
    "        for kx in np.arange(m):\n",
    "            Ykl = np.multiply(Yl, Y[kx,:].conj()) # element-wise multiply\n",
    "            for jx in np.arange(m):\n",
    "                Yjkl = np.multiply(Ykl, Y[jx,:].conj())\n",
    "                for ix in np.arange(m):\n",
    "                    Q[index] = (Yjkl*Y[ix,:].T)/T -  R[ix,jx]*R[lx,kx] -  R[ix,kx]*R[lx,jx] -  C[ix,lx]*C[jx,kx].conj()  \n",
    "                    index += 1\n",
    "\n",
    "    #% If you prefer to use more memory and less CPU, you may prefer this\n",
    "    #% code (due to J. Galy of ENSICA) for the estimation the cumulants\n",
    "    #ones_m = ones(m,1) ; \n",
    "    #T1 = kron(ones_m,Y); \n",
    "    #T2 = kron(Y,ones_m);  \n",
    "    #TT = (T1.* conj(T2)) ;\n",
    "    #TS = (T1 * T2.')/T ;\n",
    "    #R = (Y*Y')/T  ;\n",
    "    #Q = (TT*TT')/T - kron(R,ones(m)).*kron(ones(m),conj(R)) - R(:)*R(:)' - TS.*TS' ;\n",
    "\n",
    "\n",
    "\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    #%%computation and reshaping of the significant eigen matrices\n",
    "\n",
    "    D, U = eig(Q.reshape(m*m,m*m))\n",
    "    la = np.absolute(D) # la = np.absolute(np.diag(D))\n",
    "    K = np.argsort(la)\n",
    "    la = la[K]\n",
    "\n",
    "    # reshaping the most (there are `nem' of them) significant eigenmatrice\n",
    "    M = czeros((m,nem*m)) # array to hold the significant eigen-matrices\n",
    "    Z = czeros((m,m)) # buffer\n",
    "    h = m*m - 1\n",
    "    for u in np.arange(0, nem*m, m): \n",
    "        Z[:] = U[:,K[h]].reshape(m,m)\n",
    "        M[:,u:u+m] = la[h]*Z\n",
    "        h -= 1 \n",
    "\n",
    "\n",
    "\n",
    "    #%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "    #%% joint approximate diagonalization of the eigen-matrices\n",
    "\n",
    "\n",
    "    #% Better declare the variables used in the loop :\n",
    "    B = np.matrix([ [1, 0, 0], [0, 1, 1], [0, -1j, 1j ]])\n",
    "    Bt = B.H\n",
    "    Ip = czeros((1,nem))\n",
    "    Iq = czeros((1,nem))\n",
    "    g = czeros((3,nem))\n",
    "    G = czeros((2,2))\n",
    "    vcp = czeros((3,3))\n",
    "    D = czeros((3,3))\n",
    "    la = czeros((3,1))\n",
    "    K = czeros((3,3))\n",
    "    angles = czeros((3,1))\n",
    "    pair = czeros((1,2))\n",
    "    c = 0 \n",
    "    s = 0 \n",
    "\n",
    "    # init\n",
    "    V = ceye(m)\n",
    "\n",
    "    # Main loop\n",
    "    encore = True\n",
    "    n_iter = 0\n",
    "    while encore and n_iter<max_iter:\n",
    "        encore = False\n",
    "        n_iter += 1\n",
    "        for p in np.arange(m-1):\n",
    "            for q in np.arange(p+1, m):\n",
    "                Ip = np.arange(p, nem*m, m)\n",
    "                Iq = np.arange(q, nem*m, m)\n",
    "\n",
    "                # Computing the Givens angles\n",
    "                g = np.r_[ M[p,Ip]-M[q,Iq], M[p,Iq], M[q,Ip] ]\n",
    "                D, vcp = eig((B*(g*g.H)*Bt).real)\n",
    "                K = np.argsort(D) # K = np.argsort(diag(D))\n",
    "                la = D[K] # la = diag(D)[k] \n",
    "                angles = vcp[:,K[2]]\n",
    "                angles = -angles if angles[0]<0 else angles\n",
    "                c = np.sqrt(0.5+angles[0]/2.0)\n",
    "                s = 0.5*(angles[1]-1j*angles[2])/c\n",
    "                if np.absolute(s) > seuil: # updates matrices M and V by a Givens rotation\n",
    "                    encore = True\n",
    "                    pair = np.r_[p,q]\n",
    "                    G = np.matrix(np.r_[ np.c_[c, -np.conj(s)], np.c_[s, c] ])\n",
    "                    V[:,pair] = V[:,pair] * G\n",
    "                    M[pair,:] = G.H * M[pair,:]\n",
    "                    M[:,np.r_[Ip,Iq]] = np.c_[c*M[:,Ip]+s*M[:,Iq], -np.conj(s)*M[:,Ip]+c*M[:,Iq] ]\n",
    "\n",
    "\n",
    "    # estimation of the mixing matrix and signal separation\n",
    "    A = IW*V\n",
    "    S = V.H*Y\n",
    "\n",
    "    return A,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the Data\n",
    "data = sio.loadmat('data.mat')\n",
    "X = data['data'][1:13,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform JADE to get the recovered signals array (Y) and the adjancency matrix (A)\n",
    "A, Y = cjade(X, m=12, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the data\n",
    "# plt.plot(data['alldata'][0, 0:41095].T,Y[4:12, 0:41095].T)\n",
    "# plt.plot(data['alldata'][0, 0:41095].T,data['alldata'][4:12, 0:41095].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(directory):\n",
    "    \"\"\" Creates folders in the current directory called S1, S2, Recovered_S1, and Recovered_S2 \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "\n",
    "createFolder('./S1/')\n",
    "createFolder('./S2/')\n",
    "createFolder('./Recovered_S2/')\n",
    "createFolder('./Recovered_S1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeToSample(args):\n",
    "    \"\"\" Converts the time to the exact sample\"\"\"\n",
    "    return (args)*50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "offset = 0.14\n",
    "\n",
    "# The start of the heart cycle, roughly 0.8 seconds,\n",
    "# but we are counting from where S1 begins \n",
    "time_range = np.arange(offset,16.00, 0.680)\n",
    "sample_range = timeToSample(time_range)\n",
    "\n",
    "# Set where S1 and S2 Start\n",
    "begS1 = time_range + 0.03\n",
    "endS1 = begS1 + 0.1\n",
    "begS2 = begS1 + 0.27\n",
    "endS2 = begS2 + 0.06\n",
    "\n",
    "# Get their appropriate samples\n",
    "sampleS1_beg = timeToSample(begS1)\n",
    "sampleS1_end = timeToSample(endS1)\n",
    "sampleS2_beg = timeToSample(begS2)\n",
    "sampleS2_end = timeToSample(endS2)\n",
    "\n",
    "# Create a List of where the S1 and S2 samples begin and end\n",
    "B = list(zip(sampleS1_beg,sampleS1_end))\n",
    "C = list(zip(sampleS2_beg,sampleS2_end))\n",
    "\n",
    "# Pre-allocate Array space for S1\n",
    "# Space could either be 5000 or 4999\n",
    "S1_1 = np.empty([len(X),5000])\n",
    "S1_2 = np.empty([len(X),4999])\n",
    "\n",
    "# Sometimes S1 is complex\n",
    "S1_recovered1 = np.empty([len(X),5000], dtype=np.complex128)\n",
    "S1_recovered2 = np.empty([len(X),4999], dtype=np.complex128)\n",
    "\n",
    "# Pre-allocate Array space for S2\n",
    "# Space could either be 3000 or 3001\n",
    "S2_1 = np.empty([len(X),3000])\n",
    "S2_2 = np.empty([len(X),3001])\n",
    "S2_recovered1 = np.empty([len(X),3000], dtype=np.complex128)\n",
    "S2_recovered2 = np.empty([len(X),3001], dtype=np.complex128)\n",
    "\n",
    "results_1 = False\n",
    "results_2 = False\n",
    "\n",
    "# For S1 and Recovered_S1\n",
    "for i in range(len(B)): # 24 cycles (0.680 seconds)\n",
    "    for j in range(len(X)): # all mics\n",
    "        \n",
    "        # Check if we have reached 5000 samples\n",
    "        if len(data['data'][j,int(B[i][0])-1:int(B[i][1])-1]) == 5000 and Y[j, int(B[i][0])-1:int(B[i][1])-1].shape[-1] == 5000:\n",
    "            \n",
    "            # Place in S1 or S1_covered array\n",
    "            S1_1[j] = data['data'][j,int(B[i][0])-1:int(B[i][1])-1]\n",
    "            S1_recovered1[j] = Y[j, int(B[i][0])-1:int(B[i][1])-1]\n",
    "        else:\n",
    "            # Otherwise, if there are 4999 samples, place in the other array\n",
    "            S1_2[j] = data['data'][j,int(B[i][0])-1:int(B[i][1])-1]\n",
    "            S1_recovered2[j] = Y[j, int(B[i][0])-1:int(B[i][1])-1]\n",
    "            \n",
    "            # Set the boolean flag\n",
    "            results_1 = True\n",
    "    S1_filename = './S1/S1_Cycle'+str(i)+'.mat'\n",
    "    S1_recovered_filename = './Recovered_S1/S1_Cycle'+str(i)+'.mat'\n",
    "    \n",
    "    # If the flag is true, save the specifice array size\n",
    "    if results_1:\n",
    "        sio.savemat(S1_filename, {'S1':S1_2})\n",
    "        sio.savemat(S1_recovered_filename, {'S1':S1_recovered2})\n",
    "    else:\n",
    "        sio.savemat(S1_filename, {'S1':S1_1})\n",
    "        sio.savemat(S1_recovered_filename, {'S1':S1_recovered1})\n",
    "\n",
    "# For S2 and Recovered S2\n",
    "for i in range(len(C)):\n",
    "    for j in range(len(X)): \n",
    "        if len(data['data'][j, int(C[i][0])-1:int(C[i][1])-1]) == 3000 and Y[j, int(C[i][0])-1:int(C[i][1])-1].shape[-1] == 3000:\n",
    "            S2_1[j] = data['data'][j,int(C[i][0])-1:int(C[i][1])-1]\n",
    "            S2_recovered1[j] = Y[j, int(C[i][0])-1:int(C[i][1])-1]\n",
    "        else:\n",
    "            S2_2[j] = data['data'][j,int(C[i][0])-1:int(C[i][1])-1]\n",
    "            S2_recovered2[j] = Y[j, int(C[i][0])-1:int(C[i][1])-1]\n",
    "            results_2 = True\n",
    "            \n",
    "    S2_recovered_filename = './Recovered_S2/S2_Cycle'+str(i)+'.mat'\n",
    "    S2_filename = './S2/S2_Cycle'+str(i)+'.mat'\n",
    "    if results_2:\n",
    "        sio.savemat(S2_filename, {'S2':S2_2})\n",
    "        sio.savemat(S2_recovered_filename,{'S2':S2_recovered2})\n",
    "    else:\n",
    "        sio.savemat(S2_filename, {'S2':S2_1})\n",
    "        sio.savemat(S2_recovered_filename,{'S2':S2_recovered1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
